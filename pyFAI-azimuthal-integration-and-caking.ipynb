{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import logging\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import pyFAI\n",
    "import pyFAI.azimuthalIntegrator\n",
    "from pyFAI.gui import jupyter\n",
    "import fabio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO] Setup calibration using pyFAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of patterns\n",
    "## Calibration image\n",
    "The calibration image can be opened and read into an array.\n",
    "\n",
    "The array can be directly plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write the calibration file to an image array\n",
    "image = fabio.open('calibration/DLS_CeO2_1200mm.tif')\n",
    "print(\"image:\", image)\n",
    "\n",
    "calibration_image_array = image.data\n",
    "print(\"calibration_image_array:\", type(calibration_image_array), calibration_image_array.shape, calibration_image_array.dtype)\n",
    "\n",
    "jupyter.display(calibration_image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern image\n",
    "The pattern file can be opened in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the pattern file to an image array\n",
    "image = fabio.open(\"data/pixium_03150.tif\")\n",
    "\n",
    "pattern_image_array = image.data\n",
    "print(\"pattern_image_array:\", type(pattern_image_array), pattern_image_array.shape, pattern_image_array.dtype)\n",
    "\n",
    "jupyter.display(pattern_image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is in arrays, we can do things like subtract the image. This could be useful for subtracting a dark image of the detector, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_subtraction = pattern_image_array - calibration_image_array\n",
    "jupyter.display(example_subtraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example workflows for data processing\n",
    "First, we need to load the calibration, which contains information about our beamline setup, which we will use to perform an azimuthal integration or caking to the rest of our as-yet 'uncalibrated' data. To load an `azimuthal integrator` object or `ai` we use [pyFAI](https://pyfai.readthedocs.io/en/latest/).\n",
    "\n",
    "*Notes on creating a .poni calibration file using [Dioptas](http://www.clemensprescher.com/programs/dioptas) are found on the [LightForm Wiki](https://lightform-group.github.io/wiki/tutorials/sxrd-caking-dioptas)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ai = pyFAI.load(\"calibration/DLS_CeO2_1200mm.poni\")\n",
    "print(\"\\nIntegrator: \\n\", ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azimuthal integration\n",
    "\n",
    "To perform an azimuthal integration we use the `integrate1d` function. \n",
    "\n",
    "There is also an `integrate2d` function, which is designed for caking of the data.\n",
    "\n",
    "[TODO] - review all available options and determine those needed for our Diamond and DESY data.\n",
    "\n",
    "* The number of points in 2-theta is defined by the user.\n",
    "* The azimuthal range runs from -180 to 180, or -pi to pi, rather than 0 to 360 as in DAWN. An error will appear if using azimuth_range = (0,360).\n",
    "* An output .dat file can be saved, which contains a header of metadata. \n",
    "* The result is returned as a numpy array of 2-theta and intensity.\n",
    "\n",
    "An azimuthal integration can be performed like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = ai.integrate1d(pattern_image_array,\n",
    "                        npt=10000,\n",
    "                        azimuth_range=(-180,180),\n",
    "                        unit=\"2th_deg\",\n",
    "                        correctSolidAngle=True,\n",
    "                        polarization_factor=0.99,\n",
    "                        method='full_csr',\n",
    "                        filename=\"analysis/integrated.dat\")\n",
    "\n",
    "print('Size of result numpy array =', np.shape(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caking data\n",
    "\n",
    "It is possible to cake the data using a loop to iterate over segments and integrate them using `integrate1d`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_cakes = 10\n",
    "\n",
    "step = 360 / number_of_cakes\n",
    "\n",
    "data=[]\n",
    "\n",
    "for cake_number in range(number_of_cakes):\n",
    "    azimuth_low = -180 + step * cake_number\n",
    "    azimuth_high = azimuth_low + step\n",
    "    print(\"Caking range = \",azimuth_low, \" to \",azimuth_high)\n",
    "    result = ai.integrate1d(pattern_image_array,\n",
    "                            npt=1000,\n",
    "                            azimuth_range=(azimuth_low,azimuth_high),\n",
    "                            unit=\"2th_deg\",\n",
    "                            polarization_factor=0.99,\n",
    "                            method='full_csr')\n",
    "    data.append(result) \n",
    "print(\"Data array shape = \",np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, caking is easier and faster using the `integrate2d` function (as explained in the documentation [here](https://pyfai.readthedocs.io/en/latest/usage/tutorial/Introduction/introduction.html) and [here](https://pyfai.readthedocs.io/en/latest/usage/cookbook/integration_with_python.html)). \n",
    "\n",
    "Providing a file name saves the data to a file in '.edf' format. The result is returned as an `Integrate2dResult` which contains a Numpy array with the caked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = ai.integrate2d(pattern_image_array,\n",
    "                        1000,\n",
    "                        36,\n",
    "                        azimuth_range=(-180,180),\n",
    "                        unit=\"2th_deg\",\n",
    "                        polarization_factor=0.99,\n",
    "                        method='full_csr',\n",
    "                        filename = \"analysis/integrated.edf\")\n",
    "print('The result is a class of 3 arrays, with shape: ', np.shape(result))\n",
    "print('The 1st array contains the integrated intensity for each cake, with shape: ', np.shape(result.intensity))\n",
    "print('The 2nd array contains the two-theta values, with shape: ', np.shape(result.radial))\n",
    "print('The 3rd array contains the angle of the cakes, with shape: ', np.shape(result.azimuthal))\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can open the '.edf' file using FabIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cake = fabio.open(\"analysis/integrated.edf\")\n",
    "print(cake.header)\n",
    "print(\"cake:\", type(cake.data), cake.data.shape, cake.data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cake rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orientation of the cakes is explained in the accompanying `pyFAI-example-caking-with-rotation-for-xrdfit` notebook using an example image. \n",
    "\n",
    "- WEST is -180${^\\circ}$ / +180${^\\circ}$ \n",
    "- SOUTH is -90${^\\circ}$\n",
    "- EAST is 0${^\\circ}$ / 360${^\\circ}$\n",
    "- NORTH is +90${^\\circ}$\n",
    "\n",
    "pyFAI cakes the data anticlockwise (from -180${^\\circ}$ to 0${^\\circ}$ to +180${^\\circ}$) which is the opposite direction to DAWN. pyFAI also starts caking the data from the `West` (-180${^\\circ}$) direction (compared to DAWN which starts caking from the East direction).\n",
    "\n",
    "And, as shown by the result below, the minimum cake angle in pyFAI is -180${^\\circ}$, and so caking will slice along the horizontal, meaning the cake is centred on -175${^\\circ}$ cake for 10${^\\circ}$ slices, rather than being centred on the horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.azimuthal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can centre the cake on the horizontal (and vertical) by applying a rotation to the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the detector so that the cardinal direction is in the center of the first cake.\n",
    "number_of_cakes = 36\n",
    "first_cake_angle = 360 / number_of_cakes\n",
    "ai.rot3 = (first_cake_angle / 2) * (math.pi / 180) # convert rotation to radians\n",
    "print(ai.rot3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can flip the intensity data to order the cakes clockwise rather than anticlockwise. This is included in the subsequent caking multiple images example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caking multiple images\n",
    "\n",
    "To iterate through some images we can create a loop, create an array for the data and then save it as a text file.\n",
    "\n",
    "This caked dataset is now saved in a format that we can use in [xrdfit](https://xrdfit.readthedocs.io/en/stable/) to analyse how the single peak profiles change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Supress warnings when TIFFs are read\n",
    "logging.getLogger(\"fabio.TiffIO\").setLevel(logging.ERROR)\n",
    "\n",
    "# user inputs\n",
    "number_of_points = 10000\n",
    "number_of_cakes = 36\n",
    "\n",
    "# get a list of the files\n",
    "image_list = sorted(pathlib.Path(\"data/\").glob(\"pixium*\"))\n",
    "\n",
    "for image_path in image_list:\n",
    "    # create empty array\n",
    "    caked_data = np.zeros((number_of_cakes + 1, number_of_points))\n",
    "    \n",
    "    # create an image array and cake the data\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        image = fabio.open(image_path)\n",
    "    pattern_image_array = image.data\n",
    "    result2d = ai.integrate2d(pattern_image_array,\n",
    "                            number_of_points,\n",
    "                            number_of_cakes,\n",
    "                            unit=\"2th_deg\",\n",
    "                            polarization_factor=0.99,\n",
    "                            method='full_csr')\n",
    "    \n",
    "    # flip the intensity data to order cakes clockwise rather than anticlockwise\n",
    "    intensity = np.flip(result2d.intensity.T, axis=1)\n",
    "    \n",
    "    # reshape radial labels to 2D array so they can be attached to the intensity data.\n",
    "    radial = np.reshape(result2d.radial, (-1, 1))\n",
    "    \n",
    "    result_array = np.hstack((radial, intensity))\n",
    "    \n",
    "    # write out the caked data to a text file\n",
    "    output_path = f\"analysis/{image_path.stem}.dat\"\n",
    "    np.savetxt(output_path, result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result_array[:,0],result_array[:,2], marker = \".\")\n",
    "plt.xlim(3,4);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
